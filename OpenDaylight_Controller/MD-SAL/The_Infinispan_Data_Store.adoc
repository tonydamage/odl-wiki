https://wiki.opendaylight.org/images/d/db/ISPNDataStorePOC.ppt[Presentation]

[[buildingrunning-the-poc]]
= Building/Running the POC

[[yangtools]]
== yangtools

Get the latest yangtools sources and then create a branch of it using
the following command

git checkout 306ffd9eea5a52556b4877debd2a79ca0573ff0c -b
infinispan-data-store

Build using *mvn clean install -DskipTests*

[[controller]]
== controller

Get the latest controller then create a branch using the following
command

git checkout 259b65622b8c29c49235c2210609b9f7a68826eb -b
infinispan-data-store

Now apply the following gerrit

https://git.opendaylight.org/gerrit/#/c/5900/

Build using *mvn clean install -DskipTests*

when build fail

cd opendaylight/md-sal/sal-ispn-datastore

Build using *mvn clean install*

go back to controller directory

Build using *mvn clean install -DskipTests* or resume build

[[openflowplugin]]
== openflowplugin

Get the latest openflowplugin code and then create a branch using the
following command

git checkout 6affeefef4de51ce4b7de86fd9ccf51add3922f7 -b
infinispan-data-store

Build using *mvn clean install -DskipTests*

copy the sal-ispn-datastore jar to the plugins folder

[[running-the-poc]]
== Running the POC

Make sure that the 01-md-sal.xml file has been changed to use the new
MD-SAL datastore.

You should now be able to run the controller with the infinispan
datastore. If you want to do cbench testing, please follow the
instructions from later in this document.

Do note that if you want to see similar performance numbers as what we
have in this wiki you will need to disable datachange notifications. In
the POC the only way to do that is by changing the code in
ReadWriteTransactionImpl. Look for FIXME comments.

[[design-notes]]
= Design Notes

There are three major components to the infinispan data store,

1.  Encoding/Decoding a Normalized Node into and from the Infinispan
TreeCache
2.  Managing transactions
3.  Managing DataChange notifications

[[encodingdecoding-a-normalized-node-into-and-from-the-inifinispan-treecache]]
== Encoding/Decoding a Normalized Node into and from the Inifinispan
TreeCache

The first thing to understand is that a NormalizedNode represents a
tree. It's structure closely models the yang model of a bunch of
modules. The NormalizedNode tree typically has values placed in either a
LeafNode (corresponding to a leaf in yang) or a LeafSetEntryNode
(corresponding to a leaflist in yang).

The encoding logic simply walks the NormalizedNode tree looking for
LeafNodes and LeafSetEntryNodes and when it finds one it records it in a
map with the Instance Identifier of the parent as the key and the value
of the leaf or leafset entry store in a map where the NodeIdentifier of
the leaf/leafsetentry is the key and the value of the leaf/leafsetentry
is the value.

The decoding process is a little more involved. It uses the TreeCache's
interface to get to a certain node in the tree and then walks through
the tree. As it walks the tree it reconstructs the NormalizedNode based
on the key and value in the Infinispan TreeCache while at the same time
validating it against the schema.

[[managing-transactions]]
== Managing Transactions

To ensure read-write isolation level (and other reasons) we create an
infinispan (JTA) transaction for each datastore transaction. Since a
single thread may be used for multiple JTA transactions our
implementation has to ensure that we suspend and resume the JTA
transactions appropriately. This does not seem to be a big issue and it
does not seem to have an impact on performance.

[[managing-datachange-notifications]]
== Managing DataChange notifications

The current interface for data change notifications supports registering
of the listeners for notifications for data changes at Node (consider
node of a tree) level , events for any changes happen at ONE level
(meaning immediate children) Or data changes notifications for any
change in the subtree level . The event send to the listener requires
maintaining of before data change snapshot of tree and after data change
snapshot of tree. This is very expensive as we have to maintain a
Normalized Node representing snapshot of tree by converting the tree in
Infinispan to NormalizeNode object tree required by the consumer, at
beginning of each transaction.

The steps we follow to maintain the data changes are as follows:

1.  At the begin of transaction we get a NormalizedNode Object tree of
the current tree in ISPN TreeCache (this is mandated by current
DataChangeEvent interface)
2.  For each CUD operations that happens within the transaction we
maintain a transaction log
3.  When the pre-commit is called of the 3PhaseCommit Transaction
Interface-- we prepare the data changes by comparing the transaction log
items with the Snapshot Tree one taken at the beginning of the
tranasactions, preparing the DataChangeEvent lists based on what level
the listeners have registered.
4.  When commit happens we send the events to the listeners in a
separate executor(i.e asynchronously)

Suggestion

` - Remove the requirement of sending before transaction tree/after transaction tree within each event.` +
` - Just have the changed paths of tree send to the consumer and let the consumer do the reading?`

[[datastore-related-learnings]]
= Datastore related learnings

[[multiple-transactions-can-be-created-per-thread]]
== Multiple transactions can be created per thread

This is a problem because if your backing datastore (infinispan) uses
JTA transactions only one transaction can be active per thread. This
does not mean that we necessarily need to use one thread per transaction
but we do need to suspend one transaction and resume another.

Suggestion

`    - Allow only one active transaction per thread` +
`    - Add an explicit suspend/resume method on a transaction`

[[not-clear-that-read-only-transactions-need-to-be-closed]]
== Not clear that Read-Only transactions need to be closed

For every DataStore transaction we need to create a JTA transaction -
this is so that we can ensure isolation (repeatable reads) that means
that when the transaction is done we should either commit it, roll it
back or close it some fashion. With read-only transaction there may be a
tendency to not close the transactions this leads to JTA transactions
hanging around till they timeout.

Suggestion

`    - DataStore may need to do timeouts as well` +
`    - Document that close should be called explicitly for read-only transaction`

[[write-and-delete-methods-in-a-read-write-transaction-do-not-return-a-future]]
== write and delete methods in a read-write transaction do not return a
Future

write and delete methods on the DOMWriteTransaction return a void
instead of a Future. This gives the impression that these methods are
synchronous - this is not neccessarily true in all cases. For example in
the infinispan datastore the write was actually done in a separate
thread to support multiple transactions on a single thread.

Suggestion

`    - Return a ListenableFuture for both write and delete`

[[very-expensive-to-create-a-datachange-event-because-it-needs-to-pass-the-original-sub-tree-and-the-modified-sub-tree]]
== Very expensive to create a DataChange event because it needs to pass
the Original Sub tree and the Modified Sub tree

To create a DataChange event we need to create a NormalizedNode object
which may need to be a snapshot of a complete modules data so that the
original subtree can be sent to DataChange listeners. This is very
expensive and doing it on almost every transaction could be a big
problem. While we see this problem in the infinispan datastore this
would also be a big problem in a distributed system where data was
sharded to be colocated with applications and datachange listeners for
those shards on a different node on the cluster. So for example we may
have shards colocated with the inventory app and the topology app may be
a datachange listener for datachange events. In this case the original
subtree and the modified sub tree would need to be serialized in some
form and sent over to the topology listener.

Suggestion

`    - Remove the getOriginalSubtree and getModifiedSubtree methods from the datachange listener understand the use case for providing them and find a cheaper way to do the same thing`

[[reconstructing-a-normalized-node-from-a-different-data-structure-like-a-map-or-a-key-value-store-is-complicated-or-may-appear-complicated]]
== Reconstructing a Normalized Node from a different data-structure
(like a map or a key-value store) is complicated (or may appear
complicated)

A NormalizedNode is the binding-independent equivalent of data that gets
store in the datastore. For the in-memory datastore it is the native
storage format. It’s a complicated structure that basically mirrors the
model as defined in yang. Understanding it and properly decoding it
could be a challenge for folks who want to implement an alternate
datastore.

Suggestion

`    - Create utility classes to construct a normalized node from a simple tree structure. The Old CompositeNode or the Infinispan Node for example is a much simpler structure to follow.`

[[infinispan-related-learnings]]
= Infinispan related learnings

[[treecacheremovenode-api-not-working-as-expected]]
== TreeCache#removeNode API not working as expected

Haven’t had a chance to fully evaluate why but the Infinispan removeNode
API was not correctly removing nodes in the tree (as it promises). This
means for example that when a mininet topology changes some nodes may
not be removed from inventory and topology.

Action

`    - None at this time`

[[state-of-the-poc]]
= State of the POC

* Encoding/Decoding a Normalized Node into an Infinispan TreeCache works
* Integrated with the controller
* Eventing works
* With Data Change events disabled the Infinispan based datastore
performs the same or better than the custom In-Memory Datastore. While
initially it is a little slow over time it seems to perform more
consistently than the In-Memory Datastore
* Not fully tested

[[comparison-of-in-memory-and-infinispan-datastore]]
= Comparison of In-Memory and Infinispan Datastore

We used cbench to compare the performance of the two datastores.

Here is how we prepared the controller for testing,

Use the openflow plugin distribution Remove the simple forwarding, arp
handler and md-sal statistics manager bundles Set log level to ERROR Run
the controller with the following command ./run.sh -Xmx4G -Xms2G
-XX:NewRatio=5 -XX:+UseG1GC -XX:MaxPermSize=256m From the osgi command
prompt dropAllPackets on

cbench was run for 11 times for both the in-memory and infinispan
datastore versions. The first run is ignored in both cases as it does
not go through (probably another issue that needs to be looked at)

The cbench command used,

cbench -c -p 6633 -m 1000 -l 10 -s 16 -M 1000

This was a latency test and the arguments roughly translate to this,

-m 1000 : use 1000 milliseconds per test -l 10 : use 10 loops per test
-s 16 : fake 16 switches -M 1000 : use 1000 hosts per switch

The results

In-Memory Datastore

To test the in-memory datastore we downloaded a pre-built openflow
plugin distribution from Jenkins on May 1 and on this we enabled the new
in-memory datastore.

[cols=",,,,",options="header",]
|=======================================================================
|`                   Run` |`                   Min`
|`                   Max` |`                   Avg`
|`                   StdDev`
|`                   1` |`                   365`
|`                   1049` |`                   715`
|`                   04`

|`                   2` |`                   799`
|`                   1044` |`                   953`
|`                   71`

|`                   3` |`                   762`
|`                   949` |`                   855`
|`                   59`

|`                   4` |`                   616`
|`                   707` |`                   666`
|`                   27`

|`                   5` |`                   557`
|`                   639` |`                   595`
|`                   24`

|`                   6` |`                   510`
|`                   583` |`                   537`
|`                   25`

|`                   7` |`                   455`
|`                   535` |`                   489`
|`                   22`

|`                   8` |`                   351`
|`                   458` |`                   420`
|`                   38`

|`                   9` |`                   396`
|`                   440` |`                   417`
|`                   14`

|`                   10` |`                   376`
|`                   413` |`                   392`
|`                   13`
|=======================================================================

Infinispan Datastore

`       The Infinispan Datastore was built of a master which is probably a month old. Since the In-Memory datastore is hardcoded at this time we swapped the in-memory datastore for the the infinispan datastore by modifying the sal-broker-impl sources. `

`       Here is a list of some other things we did to either isolate the changes that we were making or to tweak performance,`

`       1. We used infinispan 5.3 because we wanted to isolate changes to utilize tree cache to the infinispan datastore bundles. Attempting to use version 6.0 was causing a problem in loading some classes from infinispan which we did not have the patience to chase down. Ideally if we were to use infinispan as a backing store we should tweak clustering services to obtain a treecache.`

`       2. We added a exists method onto the In-Memory ReadTransaction API. This was because we found that in one place in the BA Broker there was code which checked for the existence of nodes in the tree by doing a read. Reads are a little expensive on the Infinispan datastore because of the need to convert to a NormalizedNode so we added an exists method to the interface to just check for node-existence.`

`       3. When a transaction was used to read data it was not being closed causing the Infinispan JTA transactions to hang around. Again we made a change in the broker to ``close`` a transaction after it was done with so that it was not left hanging around and did not trigger a clean by the reaper.`

[cols=",,,,",options="header",]
|=======================================================================
|`                       Run` |`                       Min`
|`                       Max` |`                       Avg`
|`                       StdDev`
|`                       1` |`                       43`
|`                       250` |`                       186`
|`                       61`

|`                       2` |`                       266`
|`                       308` |`                       285`
|`                       13`

|`                       3` |`                       300`
|`                       350` |`                       325`
|`                       12`

|`                       4` |`                       378`
|`                       446` |`                       412`
|`                       24`

|`                       5` |`                       609`
|`                       683` |`                       644`
|`                       26`

|`                       6` |`                       492`
|`                       757` |`                       663`
|`                       76`

|`                       7` |`                       794`
|`                       838` |`                       816`
|`                       11`

|`                       8` |`                       645`
|`                       845` |`                       750`
|`                       60`

|`                       9` |`                       553`
|`                       829` |`                       708`
|`                       100`

|`                       10` |`                       615`
|`                       910` |`                       710`
|`                       86`
|=======================================================================

