===[[Detailed Defense4All Introduction:Introduction|Introduction]] ===
A well-known DoS attack mitigation and threats detection strategy is to divert suspected traffic from its normal network path to dedicated attack mitigation infrastructures, for cleaning and threat detection. These infrastructures are also known as “Security Centers” or “Scrubbing Centers”, mainly built of L3-L7 DoS attack mitigations devices. These “Security Centers” can be deployed in dedicated remote sites within the network in “out of path” manner (i.e. not “inline” with the native traffic flow), so diversion of traffic toward these centers is essential. During the traffic cleaning process, the attack mitigation infrastructure identifies and drops malicious IP packets and forwards legitimate IP packets back to their original targeted network destinations. The “Scrubbing Centers” can be located within the enterprise cooperate network, datacenter, cloud and also as part of carrier’s infrastructure.   
In general protection against DDoS attacks in Out-Off-Path (OOP) systems comprises three main elements: 
# Collection of traffic statistics and learning of statistics behavior of protected objects during peace-time. From this collected statistics, the normal traffic baselines of the protected objects are built.  
# Detection of DoS attack patterns as traffic anomalies deviating from normal baselines.  
# Diversion of suspicious traffic from its normal path to mitigation (scrubbing) centers for traffic cleansing, selective source blockage, etc.  “Clean” traffic out of scrubbing centers is re-injected back to packet’s original destination. 
Defense4All is a security SDN application for detecting and driving mitigation of DoS/DDoS attacks in different SDN topologies. It realizes anti-DoS in Out Of Path mode for OpenDaylight SDN environment. Administrators can configure Defense4All to protect certain networks/servers (henceforth, protected networks or PNs). 

Defense4All exploits SDN capabilities to count specified traffic, and installs traffic counting flows for each protocol of each configured PN in every network location through which traffic of the subject PN flows. Defense4All then monitors traffic of all configured PNs, summarizing readings, rates, and averages from all relevant network locations. In case it detects a deviation from normal learned traffic behavior in some protocol (TCP, UDP, ICMP, or rest of the traffic) of some PN, Defense4All declares an attack against that protocol in the subject PN. 

To mitigate a detected attack Defense4All performs several steps: 1) It selects one or more mitigation devices to mitigate the attack. 2) It configures SDN to divert attacked traffic through the mitigation devices. 3) It continues monitoring attacked traffic both from SDN and (optionally) from mitigation devices. When Defense4All receives no indications about the attack it cancels attacked traffic diversions and returns to peace-time monitoring.

Administrators need to notify Defense4All about relevant SDN controller, switches/routers, and mitigation devices of choice. Defense4All users can retrieve all present and past information about PN learned traffic normal, attacks and mitigations, health and status of mitigation devices and links, SDN configurations, and other operational information. Past information is stored in persistent flight recorder storage.

In this version Defense4All runs as a single instance (non-clustered), but it integrates three main fault tolerance features - 1) it runs as a Linux service that is automatically restarted should it fail, 2) its state is entirely persisted in stable storage, and upon restart Defense4All obtains the latest state, and 3) it carries a health tracker with restart and (several degrees of) reset capabilities to overcome certain logical and aging bugs.

Defense4All is designed for pluggability, allowing integration of different types of mitigation devices [Defense4All contains a reference implementation of a driver to Radware’s mitigation device – DefensePro. To attach some other mitigation device one needs to integrate driver to that device into Defense4All.], different SDN and non-SDN based attack detectors, different mitigation drivers, and different abstraction levels of network controller functionality for collecting traffic statistics and for traffic diversion. Finally, Defense4All itself resides in a framework, and can be replaced by other SDN applications [SDN and mitigation device drivers should be repackaged into the framework rather than Defense4All].

The diagram below describes the possible state of any given PN. Radware DefensePro, abbreviated as "DP" is an example of an incorporated AMS.
[[File:pn_possible_states.jpg|none|900px|PN possible states]]

===[[Detailed Defense4All Introduction:Deployment alternatives|Deployment alternatives]] ===
Defense4All supports “short diversion”, in which the AMS (Attack mitigation system) is connected to the edge router, so one hop traffic redirection is achieved. See also PE1 and DefensePro 2 in Figure 3. “Long diversion”, in which AMS scrubbing centers are located in arbitrary remote locations in the network, may be added in future Defense4All versions. See also PE2 and DefensePro 1 in Figure below.  
Defense4All supports both automatic and manual diversion modes. The manual mode includes user-based confirmation before diversion.
[[File:redirection_alternatives.jpg|none|900px|Defense4All Deployment traffic redirection alternatives]]

===[[Detailed Defense4All Introduction:Structure |Structure ]] ===
Defense4All is an SDN application for detecting and mitigating DDoS attacks. Figure 3 depicts its positioning in OpenDaylight environment. The application communicates with OpenDaylight Controller via the ODC north-bound REST API. Through this API Defense4All performs two main tasks:
# Monitoring behavior of protected traffic - the application sets flow entries in selected network locations to read traffic statistics for each of the PNs (aggregating statistics collected for a given PN from multiple locations).
# Diverting attacked traffic to selected AMSs – the application set flow entries in selected network locations to divert traffic to selected AMSs. When an attack is over the application removes these flow entries, thus returning to normal operation and traffic monitoring.
Defense4All can optionally communicate with the defined AMSs – e.g., to dynamically configure them, monitor them or collect and act upon attack statistics from the AMSs. The API to AMS is not standardized, and in any case beyond the scope of the OpenDaylight work. Defense4All contains a reference implementation pluggable driver to communicate with Radware’s DefensePro AMS.
The application presents its north-bound REST and CLI APIs to allow its manager to:
# Control and configure the application (runtime parameters, ODC connectivity, AMSs in domain, PNs, etc.).
# Obtain reporting data – operational or security, current or historical, unified from Defense4All and other sources (like ODC, AMSs).
[[File:D4A_in_odl.jpg|none|600px|Defense4All logical positioning in OpenDaylight environment]]
Defense4All comprises an SDN applications Framework and the Defense4All application itself – packaged as a single entity. Application integration into the Framework is pluggable, so any other SDN application can benefit from the common Framework services. The main advantages of this architecture are:
# Faster application development and changes - the Framework contains common code for multiple applications, complex elements (e.g., clustering or repository services) are implemented once for the benefit of any application.
# Faster, flexible deployment in different environments, form-factors, satisfying different NFRs – the Framework masks from SDN applications factors such as required data survivability, scale and elasticity, availability, security.
# Enhanced robustness - complex Framework code is implemented and tested once, cleaner separation of concerns leads to more stable code, Framework can increase robustness proactively with no additional code in application logic (e.g., periodic application recycle).
# Unified management of common aspects – common look and feel.
===[[Detailed Defense4All Introduction:Framework View|Framework View]] ===
[[File:framework_view.jpg|none|900px|Defense4All Structure from Framework point of view]]
The Framework contains the following elements:

'''FrameworkMain''' – the Framework root point contains references to all Framework modules and global repositories, as well as the roots of deployed SDN applications (in current version the Framework can accommodate only one). This is also the point to start, stop or reset the Framework (along with its hosted application)
WebServer – Jetty web server running the Jersey RESTful Web Services framework, with Jackson parser for JSON encoded parameters. The REST Web Server runs a servlet for Framework and another servlet for each deployed application (currently only one). All REST and CLI APIs are supported through this REST Web Server.

'''FrameworkRestService''' – A set of classes constituting the Framework Servlet that responds to Framework REST requests (e.g., get latest Flight Recorder records, perform factory reset, etc.). The FrameworkRestService invokes control and configuration methods against the FrameworkMgmtPoint, and for reporting it retrieves information directly from the relevant repositories. For flight recordings it invokes methods against the FlightRecorder.

'''FrameworkMgmtPoint''' – Is the point to drive control and configuration commands (e.g., start, stop, reset, set address of the hosting machine, etc.). FrameworkMgmtPoint invokes in turn methods against other relevant modules in the right order. It forwards lifecycle requests (start, stop, reset) directly to FrameworkMain to drive them in the right order.
'''Defense4All Application''' – Is the AppRoot object that should be implemented/extended by any SDN application – in our case Defense4All. SDN Applications do not have “main”, and their lifecycle (start, stop, reset) is managed by the Framework operating against the Application root object, which then drives all lifecycle operations in the application. This module also contains reference back to the Framework, allowing the application to use Framework services (e.g., create a Repo, log a flight record) and common utilities.
'''Common classes and utilities''' – is a library of convenience classes and utilities, from which any Framework or SDN Application module can benefit. Examples include wrapped threading services (for asynchronous, periodic or background execution), short hash of a string, confirmation by user, etc.

'''Repository services''' – One of the key elements in the Framework philosophy is decoupling compute state from compute logic. All durable state should be stored in a set of repositories that can be then replicated, cached, distributed under the covers –with no awareness of the compute logic (Framework or Application). Repository services comprise the RepoFactory and Repo or its annotations friendly equivalent – the EntityManager. The RepoFactory is responsible to establish connectivity with the underlying Repository plugged in service, instantiate new requested repositories and return references to existing ones. The chosen underlying Repository service is Hector Client over Cassandra NoSQL DB. Repo presents an abstraction of a single DB table. It allows reading the whole table, only table keys (tables are indexed by only the single primary key), records or single cells, as well as writing records or single cells with controlled eagerness. A sub-record (with only a portion of cells) may be written. In such a case the appearing cells override existing ones in the repository. Other cells in the repository remain unchanged. In contrast to relational DB, in which all columns must be specified up-front (in schema design), Repo leverages the underlying Cassandra support to contain rows (records) in the same table with different sets of columns, some of which may not being even defined up-front. Furthermore, cells with new columns can be added or removed on the fly. RepoFactory and Repo (as well as its Entity Manager annotation friendly equivalent) constitute a convenience library targeted to Framework and SDN Applications goals – on top of the Hector client library communicating with Cassandra Repository cluster. Scaling Cassandra cluster, distributing data shards across Cassandra cluster members, configuring read/write eagerness and consistency – are for the most part encapsulated in this layer. 

'''Logging and Flight Recorder services''' – The logging service simply uses Log4J library to log error, warning, trace or informational messages. These logs are mainly for Defense4All developers. Administrators can obtain additional details about failures from errors log. FlightRecorder records all flight records recorded by any Defense4All module, including information received from external network elements, such as ODC, AMSs, etc. It then allows a user/administrator to obtain that information through REST/CLI. Flight records can be filtered by categories (zero or more can be specified) and by time ranges. FlightRecorder stores all flight records in its own Repo (with another repo holding time ranges for efficient time ranges retrieval from the records repo). Because all flight records are stored in Cassandra, the number of flight records Defense4All can keep is limited only by the size of the underlying persistent storage capacity of all Cassandra servers, and so even on a single Cassandra instance months of historical information can be kept.

'''HealthTracker''' – Is the point to hold the aggregated runtime health of Defense4All, and to act in response to severe deteriorations. Any module, upon sensing an unexpected/faulty behavior in it or in any other module can record a “health issue” in the HealthTracker, providing health issue significance. This is instead of directly triggering Defense4All termination. The idea is that numerous health issues in a short period of time with high aggregated significance are likely to indicate a significant wide-spread Defense4All problem, but sporadic/intermittent operational “hiccups” can be neglected – even if Defense4All remains less than 100% operational (the administrator can always reset restart it to fully recover). As such, every non-permanent health issue has a gradually diminished affect over time. If Defense4Al health deteriorates below a predefined threshold HealthTracker triggers responsive actions – depending on the nature of health issues. A restart can heal transient problems, and so the HealthTracker triggers Defense4All termination (running as a Linux service Defense4All will be automatically restarted). To recover from more permanent problems HealthTracker may additional trigger a Defense4All reset. If it does not help then the next time the HealthTracker will attempt a more severe reset. As a last resort the administrator can be suggested to perform factory reset.

'''ClusterMgr''' – Currently not implemented. This module is responsible for managing a Defense4All cluster (separate from Cassandra or ODC clusters, modeled as separate tier clusters). A clustered Defense4All carries improved high availability and scalability. Any module in Defense4All Framework or Application can register with ClusterMgr for clustered operation, specifying whether its functionality should be carried out by a single or by multiple/all active instances (running on different Defense4All cluster members). When cluster membership changes, ClusterMgr notifies each instance in each module about its role in the clustered operation of that module. In case of a single active instance that instance is told so, while all other instances are told they are standby. In case of multiple active instances, each active instance is notified about the number of active instances, and its logical enumeration in that range. All state is stored in a globally accessible and shared repository, so any instance of a module is stateless, and can perform any role after every membership change. For example, following membership change N an instance can be enumerated as 2 out of 7, and thus perform relevant portion of the work. Then at membership change N+1 the same instance can be enumerated 5 out of 6, and perform the work portion allocated for 5 and not for 2. We skip the peer messaging services which the ClusterMgr can provide for a more coordinated cross-instance operation.

The Defense4All Application is highly pluggable - it can accommodate different attack detection mechanisms, different attack mitigation drivers, and drivers (called reps – short for representative) to different versions of ODC and different AMSs. Defense4All Application comprises “core” modules and “pluggable” modules implementing well-defined Defense4All Application APIs. 

===[[Detailed Defense4All Introduction:Defense4All Application View|Defense4All Application View]] ===
[[File:d4a_application_view.jpg|none|900px|Defense4All Defense4All Application Structure]]

The Defense4All Application modules are described below:

'''DFAppRoot''' – This is the root module of the Defense4All Application. As mentioned before, the Defense4All Application does not have “main”, and its lifecycle (start, stop, reset) is managed by the Framework operating against this module, which in turn drives all lifecycle operations in the Defense4All Application. DFAppRoot also contains references to all Defense4All Application modules (core and pluggable), global repositories, and reference back to the Framework, allowing the Defense4All Application modules to use Framework services (e.g., create a Repo, log a flight record) and common utilities.

'''DFRestService''' – A set of classes constituting the Defense4All Application Servlet that responds to Defense4All Application REST requests. The DFRestService invokes control and configuration methods against the DFMgmtPoint, and for reporting it retrieves information directly from the relevant repositories. For flight recordings it invokes methods against the FlightRecorder.

'''DFMgmtPoint''' – The point to drive control and configuration commands (e.g., addams, addpn). DFMgmtPoint invokes in turn methods against other relevant modules in the right order.

'''ODL Reps''' – Is a pluggable module-set for different versions of ODC. Comprises two functions in two sub-modules – stats collection for and traffic diversion of relevant traffic. These two sub-modules adhere to StatsCollectionRep DvsnRep APIs. ODL Reps is detailed in Figure 6 and description that follows it.
SDNStatsCollector – Is responsible to set “counters” for every PN at specified network locations (physical or logical). A counter is a set of OpenFlow flow entries in ODC enabled network switches/routers. The SDNStatsCollector periodically collects statistics from those counters and feeds them to the SDNBasedDetectionMgr (see next). The module uses the SDNStatsCollectionRep to both set the counters and read latest statistics from those counters. A stat report consists of read time, counter specification, PN label, and a list of trafficData information, where each trafficData element contains latest bytes and packets values for flow entries configured for <protocol,port,direction> in the counter location. Protocol can be {tcp,udp,icmp,other ip}, port is any layer 4 port, and direction can be {inbound, outbound}.

'''SDNBasedDetectionMgr''' – Is a container for pluggable SDN based detectors. It feeds stat reports, received from SDNStatsCollector, to plugged-in SDN based detectors. It also feeds to all SDN based detectors notifications from AttackDecisionPoint (see ahead) about ended attacks (so as to allow reset of detection mechanisms). 

'''RateBasedDetector sub-module''' – This detector learns for each PN its normal traffic behavior over time, and notifies AttackDecisionPoint (see next) when it detects traffic anomalies. For each protocol {tcp, udp, icmp, other ip} of each PN the RateBasedDetector maintains latest rates and exponential moving averages (baselines) of bytes and packets, as well as last reading time. The detector maintains those values both for each counter as well as aggregation of all counters for each PN. The organization at two levels of calculations (counter and PN aggregate) allows for better scalability (e.g., working with clustered ODC, where each instance is responsible to obtain statistics from a portion of network switches, and bypassing the ODC single instance image API).  Such organization also enables a more precise stats collection (avoiding the difficulty to collect all stats during a very small time interval). Stats are processed at the counter level, and periodically aggregated at the PN level. Continuous detections of traffic anomalies cause the RateBasedDetector to notify AttackDecisionPoint about attack detection. Then absence of anomalies for some period of time causes the detector to stop notifying AttackDecisionPoint about attack detection. The detector specifies a detection duration – time within which the detection is valid. After that time the detection expires, but can be “prolonged” with another notification about the same attack.

'''AttackDecisionPoint''' – This module is responsible to maintain attack lifecycles. It can receive attack detections from multiple detectors. Defense4All supports the RateBasedDetector, external detectors (in future versions), and AMS based detector reference implementation (over Radware’s DefensePro). In current version AttackDecisionPoint fully honors each detection (max detector confidence, max detection confidence). It declares a new attack for every detection of a new attacked traffic (PN, protocol, port), and add more detections for existing (already declared attacks). The module checks periodically the statuses of all attacks. As long as there is at least one unexpired detection (each detection has an expiration time) attack is kept declared. If all detections are expired for a given attack AttackDecisionPoint declared attack end. The module notifies the MitigationMgr (see next) to start mitigating any new declared attack. It notifies the MitigationMgr to stop mitigating ended attacks, and also notifies the detectionMgr to reset stats calculations for traffic on which an attack has just ended.
 
'''MitigationMgr''' - Is a container for pluggable mitigation drivers. The MitigationMgr maintains the lifecycle of all mitigations, resulted from mitigation notifications from AttackDecisionPoint. It holds a pre-ordered list of the MitigationDriver sub-modules, and attempts to satisfy each mitigation in that order. If MitigationDriveri indicates to MitigationMgr that it does not mitigate a mitigation (because of per PN preferences, unavailability of AMS resources, network problems, etc.) MitigationMgr will attempt mitigation by MitigationDriveri+1. If none of the plugged-in MitigationDrivers handle mitigation it remains in status ‘not-mitigated’. 

'''MitigationDriverLocal''' – This mitigation driver is responsible to drive attack mitigations using AMSs in its sphere of management. When requested to mitigate an attack this mitigator performs the following sequence of steps:
# It consults with the plugged in DvsnRep (see ahead) about topologically feasible options of diversion to each of the managed AMSs from each of the relevant network locations. In this version diversion is always done from the location where the stats counters are installed. 
# The MitigationDriverLocal then selects an AMS out of all feasible options (in the first release the selection is trivial – first in list.
# It optionally configures all the AMSs (each diversion source may have a different AMS associated with it) prior to instructing to divert traffic to each. This is done through the plugged in AMSRep. 
# The MitigationDriverLocal instructs the DvsnRep to divert traffic from each source NetNode (in this version NetNode is modeled over an SDN Switch) to the AMS associated with that NetNode. Diversion can be either for inbound traffic only or both for inbound and outbound traffic.
# The mitigation driver notifies the AMSBasedDetector to optionally start monitoring attack status in all the AMSs, and feed attack detections to AttackDecisionPoint.
# In future versions the MitigationDriverLocal should monitor health of all AMSs and relevant portions of network topologies, re-selecting AMSs should some fail, or should network topologies changes require that.
When mitigation should be ended the MitigationDriverLocal notifies AMSBasedDetector to stop monitoring attack status for the ended attack, notifies DvsnRep to stop traffic diversions to all AMSs – for this mitigation, and finally notifies the AMSRep to optionally clean all mitigation related configuration set in each relevant AMS.

'''AMSBasedDetector''' – This optional module (can be packaged as part of the AMSRep) is responsible for monitoring/querying attack mitigation by AMSs. Registering as a detector this module can then notify AttackDecisionPoint about attack continuations and endings. It monitors only specified AMSs and only for specified (attacked) traffic.

'''AMSRep''' - Is a pluggable module for different AMSs. The module adheres to AMSRep APIs. It can support configuration of all introduced AMSs (permanently or before/after attack mitigations). It can also receive/query security information (attack statuses), as well as operational information (health, load). AMSRep module is entirely optional – AMSs can be configured and monitored externally. In many cases attacks can continue be monitored solely via SDN counters. Defense4All contains a reference implementation AMSRep that communicates with Radware’s DefensePro AMSs.

a
