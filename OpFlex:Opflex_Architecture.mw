== OpFlex Policy Agent Architecture ==

=== The Fine Print ===
This document is considered a working document in that it is intended to be a place holder for the project and as the Policy Agent under goes development, this document will change as well and at time be outdated.

=== Overview ===
This document describes the architecture proposed for the open source Policy Agent for the implementation that will implement the OpFlex protocol. Before one discusses the details of the architecture and assumptions therein, an overview of where and how the Policy Agent will fix into and overall  system design is in order. The following is that overview of a Policy systems and its various functions.
The policy agent’s function is to exchange and enforce policy, acting as a participant in a larger policy management system.  policy system. Figure 1-1 is an example of such a system. The agent is a Policy Element (PE), which requests Policy Resolution and receives Policy Updates from a Policy Repository (PR). The agent can also indicate the declaration of new End Points to an End Point Registry (EPR), and receive Policy Resolutions and Updates for the End Points. Status information is sent to an Observer, which collects and archives the status. The agent can also trigger behaviors in peering Policy Elements, using the Policy Trigger message. A more complete description of an Policy system can be found in [1].

[[File:S1mdMlrjSoE4t3CGd59GX8A.png]]


==== Policy and Policy Resolution ====
A primary function of the policy architecture is the delivery and maintenance of Manage Object (MO) subtrees. Each Policy Element has a Managed Object Store, which provides a means for local caching of policy in the form of Managed Objects. Managed Objects are considered subtrees of a larger Management Information Tree (MIT). The MIT is the superset of all possible policies, and is generated from a user-defined policy model. There are two types of policy models. One is a “Logical Model” in which fabric-specific details are abstracted into an equivalent logical representation. The other is a “Concrete Model” in which the objects in the model refer to physical network elements. The Logical Model is used to create a MIT that can be imported in the policy controller, as well as MO library that can be integrated in the agent (Figure 1-3).


[[File:SoQ8NTo_lvD95rDSmZRQ-Ow.png ]]

'''Figure 1-3: Generated Policy Model'''

Each type of policy is uniquely identified in a given context by its name, where context can be specific to a tenant, a shared common tenant, etc. Resources that use a policy refer to this policy by its name, and a hierarchical closest matching policy is resolved. If no named match exists, a default policy is resolved.

Policy resolution is typically implicit, meaning that it is triggered via a set of internal APIs in the PE as a side effect of a change / stimulus, such as an endpoint attach. Policy resolution consists of sending logical policies to Policy Elements, which maintain read-only copies of the logical policies and apply changes to corresponding concrete model objects. Whenever possible, sets of related policies are resolved together in a single transaction to Policy Elements.

The Policy Repository persists information about which policies are in use and where they have been resolved in an internal registry. When there are subsequent changes to policies -- such as property modifications and lifecycle changes (creation, deletion) -- the Policy Repository sends update notifications to Policy Elements where the affected policies are in use. It is the responsibility of Policy Repository to push the updates to policies that it owns to all the policy clients of the policy. For each policy, the Policy Repository maintains the list of policy clients and policy consumers. As mentioned in above, when a policy is resolved, all policies with that name in the hierarchy are in-scope policies and would be resolved. Whenever a policy is updated, the updated policy is pushed down to all policy clients. The Policy Update message is only used to provide updates to policies that have already been provided to a Policy Element, and not to install an entirely new policy. The Policy Resolution message from the Policy Element must be used to request new policies (i.e. MO sub-trees that the PE doesn’t yet have).

=== OpFlex Background ===
To implement declarative control, a new mechanism is required to transfer abstract policy from a network policy controller to a set of smart devices capable of rendering abstract policy. Unfortunately, existing protocols such as OVSDB favor imperative models and rigid schematics, so they are not appropriate for this use case. In Fact, devOps tools such as Puppet or CFEngine take a similar approach to OpFlex in using declarative languages to configure server resources.

OpFlex was designed to augment rather than replace these tools by focusing on additional requirements of the network and policies that must span multiple network devices. For example, OpFlex includes a native mechanism for identity resolution used to define declarative policies between two different network endpoints.Cisco, along with partners including Microsoft, Red Hat, Citrix, F5, Canonical, and Embrane, developed OpFlex to address this challenge. OpFlex is an open and extensible policy protocol for transferring abstract policy in XML or JavaScript Object Notation (JSON) between a network policy controller such as the Cisco APIC and any device, including hypervisor switches, physical switches, and Layer 4 through 7 network services. Cisco and its partners are working through the IETF and open source community to standardize OpFlex and provide a reference implementation.

[[File:CFPOpflexDrawing1.jpg]]

=== OpFlex Description ===
 
OpFlex is designed to allow a data exchange of a set of managed objects that is defined as part of an informational  model. OpFlex itself does not dictate the information model and can be used with any tree-based abstract model in which each node in the tree has a universal resource identifier (URI) associated with it. 

The protocol is designed to support XML and JSON (as well as the binary encoding used in some scenarios) and to use standard remote procedure call (RPC) mechanisms such as JSON-RPC over TCP. The use of a secure channel through Secure Sockets Layer (SSL) and Transport Security Layer (TSL) is also recommended. 

The protocol defines a number of logical constructs required for its operation (Figure 2). 
 
[[File:Don2.jpg]]


==== Policy Repository ====
The policy repository (PR) is a logically centralized entity containing the definition of all policies governing the behavior of the system. In Cisco ACI, this function is performed by the Cisco APIC or by the leaf nodes of the network fabric. The policy authority handles policy resolution requests from each policy element. 

==== Policy Element (Policy Agent) ====
A policy element (PE) is a logical abstraction for a physical or virtual device that implements and enforces policy. This is where the Policy Agent describe in detail herein resides. Policy elements are responsible for requesting portions of the policy from the policy authority as new endpoints connect, disconnect, or change. Additionally, policy elements are responsible for rendering that policy from an abstract form into a concrete form that maps to their internal capabilities. This process is a local operation and can function differently on each device as long as the semantics of the policy are honored. 

==== Endpoint Registry ==== 
The endpoint registry (ER) stores the current operation state (identity, location, etc.) of each endpoint (EP) in the 
system. The endpoint registry receives information about each endpoint from the local policy element and then can share it with other policy elements in the system. The endpoint registry may be physically co-located with the policy authority, but it may also be distributed in the network fabric itself. In Cisco’s ACI solution, the endpoint registry actually lives in a distributed database within the network itself to provide additional performance and resiliency.

=== Opflex Protocol Messages ===

Table 1 Summarizes the RPC methods that OpFlex supports. It is not intended to provide a full description, but to to show how different entities interact through the protocol.


Table 1. RPC Methods Supported by OpFlex.

[[File:Don3.jpg]]

== Policy Agent Architecture Discussion ==
The Policy Agent (PA) provides a framework for creating families of policy agents, enabling policy enforcement across a wide variety of functions, such as compute, storage, and networking.  The agent connects to other components in the policy fabric, and interacts with them to manage its policy state. The PA diagram shown in Figure 3.0, is the basic building blocks that are to be discussed in the following sections. For the most part there are 3 section that makeup the design.

[[File:PolicyAgentOverview.jpg]]
 

# Policy Management - responsible for the communications to the policy systems (i.e. ODL, Openstack, APIC, etc.), and the marshaling of the OpFlex protocol into the Managed Objects (MOB). 
## This will encompass a stream Based communications API and can easily support multiple protocols, i.e. TCP/UDP/SSL.
### The streams interface will support both active, initiate connections to the controller, and passive based communications, listener.
### Will support a plug-able payload data marshaling and de-marshaling for JSON and XML.
### Protocol management will be implemented in this layer as well. Protocol management will instigate the initiation of communications to the policy controllers and the re-establishment of connection upon a failure. 
#### This implies that as discovery of policy entities occurs their details will be persisted to the file system such that they can be recovered upon a restart of the of the PA.
# Managed Objects DB (MODB) - this represent that accumulation of policies that have been rendered into a hierarchical tree model and represent real-time status from the actual physical devices under enforcement. An abstract representation of network resources that are managed. With "representation", I mean not the actual device that is managed, but also the device driver, that communicates with the device.The database, where all managed objects are stored, is called the Managed Object Database . The MO is "dynamic" and communicates with other network resources that are managed.
# Policy Enforcement - This layer presents itself as a series for APIs that are leverage to communicate to devices under management (i..e. switches, routers, storage, compute nodes, etc.). The intention here is to provide a plugable interface such that the Policy agent can be used with multiple devices.
## Initially, the OpenvSwitch (OVS) using OpenFlow v1.4 will be target as a representative implementation.

=== Policy Management Layer ===
The policy management layer embodies the communications to the north bound of the PA and the protocol management, in the case of this design it will be OpFlex, but it would not preclude another policy protocol. This layer consist of the following sections of development: 
# Stream API 
# Session Manager
# Presentation Manager
 
[[File:PAMgmtLayer.jpg]]

==== Stream API ====
This would be base on the OVS library stream interface where the actual details protocol being used for communications is abstracted from the upper layer. A stream_class is present which provides the necessary call-backs to support the underlying protocols (i.e. TCP, SSL, RPCJSON). This approach obviously provides a framework from which to add further protocol support. The pstream_class definition is as follows:

struct pstream_class {
    /* Prefix for connection names, e.g. "ptcp", "pssl", "punix". */
    const char *name;

    /* True if this pstream needs periodic probes to verify connectivity.  For
     * pstreams which need probes, it can take a long time to notice the
     * connection was dropped. */
    bool needs_probes;

    /* Attempts to start listening for stream connections.  'name' is the full
     * connection name provided by the user, e.g. "ptcp:1234".  This name is
     * useful for error messages but must not be modified.
     *
     * 'suffix' is a copy of 'name' following the colon and may be modified.
     * 'dscp' is the DSCP value that the new connection should use in the IP
     * packets it sends.
     *
     * Returns 0 if successful, otherwise a positive errno value.  If
     * successful, stores a pointer to the new connection in '*pstreamp'.
     *
     * The listen function must not block.  If the connection cannot be
     * completed immediately, it should return EAGAIN (not EINPROGRESS, as
     * returned by the connect system call) and continue the connection in the
     * background. */
    int (*listen)(const char *name, char *suffix, struct pstream **pstreamp,
                  uint8_t dscp);

    /* Closes 'pstream' and frees associated memory. */
    void (*close)(struct pstream *pstream);

    /* Tries to accept a new connection on 'pstream'.  If successful, stores
     * the new connection in '*new_streamp' and returns 0.  Otherwise, returns
     * a positive errno value.
     *
     * The accept function must not block waiting for a connection.  If no
     * connection is ready to be accepted, it should return EAGAIN. */
    int (*accept)(struct pstream *pstream, struct stream **new_streamp);

    /* Arranges for the poll loop to wake up when a connection is ready to be
     * accepted on 'pstream'. */
    void (*wait)(struct pstream *pstream);

    /* Set DSCP value of the listening socket. */
    int (*set_dscp)(struct pstream *pstream, uint8_t dscp);
};

It is important to note that all the socket interface are perform in a non-blocking mode. Using this layer to perform connection initiation is fairly obvious but  to perform listener its basically a stream.c:pstream_accept which will not block waiting for a connection. If no connection is ready to be accepted, it returns EAGAIN immediately. But if block is desired, as is with most listeners, there is also stream.c:pstream_accept_block, which does block until a connection is ready or until an error occurs.

==== Session Manager ====
The session manager (SM) layer should support the ability to provide a connection list of active and inactive connections, defined by a state of the connection. Connection to north bound systems should be held open until either they are closed by the PA or the peer on the the other end. The connection list should be defined by the config file variable and if the connection list is full, the LRU (Least Recently Used) policy should be used to either open or accept another connection. 
In addition, a session timeout thread should be used to timeout sessions in the session list. This timeout will be config file controlled. The reason for keeping the session list efficient is if there is no need to keep a connection active, i.e. lack of activity, then its best to free up the session list slot and the memory that a connection consumes. The SM should have the ability to perform marshaling/de-marshaling of data based upon the connection and the presentations managers connection setup information. OpFlex provides a Identify message which will provide the type connectivity_info and roles information.
The session manager layer should also be the identity that sets up the PA's listener based upon configuration information found in the config file.

==== Presentation Manager ==== 
The Presentation Manager (PM) establishes context OpFlex entities, in which the OpFlex entities may use different syntax and semantics see OpFlex IETF draft, draft-smith-opflex-00b  specification.  The dealings of OpFlex protocol, i.e. Discovery and Identify.
This layer provides independence from data representation (e.g., JSON)/XML/etc.) by translating between application and network formats. The presentation layer transforms data into the form that the application accepts. This layer formats and encrypts data to be sent across a network. It is sometimes called the syntax layer.
As the presentation Layer discovers items in the policy network (i.e. controllers, policy repositories (prime data and replicated data), this layer should make a map of this information which should include the enough details such that it can be persisted to disk. Each time the PA initializes (e.g. after a crash), and if the file is available on disk, it should be assumed that the information should be restored from this file and the presentation layer should try and re-establish connections to all know systems (i.e. identify message). This allow that if in the case of a failure of the PA, it can recover its connections to try and ensure establishment to the policy systems. This will speed up the crash recovery because each policy that is in the MODB will have to be re-confirmed (rendered with the upper controllers).

=== Managed Objects Database (MODB) ===
This represent that accumulation of policies that have been rendered into a hierarchical tree model and represent real-time status from the actual physical devices under enforcement. An abstract representation of network resources that are managed. With "representation", I mean not the actual device that is managed, but also the device driver, that communicates with the device.The database, where all managed objects are stored, is called the Managed Object Database . The MO is "dynamic" and communicates with other network resources that are managed. 
The MODB is essentially an accumulation of lists and hash lookup tables that are designed for usability for the policy storage and for quick retrieval of data though a common API. The MODB's lookups are some what static in that they are designed for optimum index to data that we will support look ups for. By no means are they static in the sense that data in those index look ups table will be static its just the optimized look ups will be support using the index look ups.
The structure of the MODB is showing in Figure 3-1. The Figure is intended to give a general idea of the internal structure of the MODb and its relationship to the indexing and the API that both the southbound and northbound interface will use to access it.
 
[[File:MODB.jpg]]
'''Figure 3-1'''

At the core of the model is the Node entity that will define all data relationships in the system. One node's difference from another will be defined by its lri and class_id. For example a chassis verses a port will be defined by different class_ids, but each individual port will be differentiated by its id and uri. This allows for the model to be very simplistic but very functional. Each node will associated to its parent, assuming it has one, if not this will NULL, and its children, which will just be a list head pointing to the lik list of all the nodes that make up its children nodes. An example of an abstracted model is shown in Figure 3-2, where each of the items (i.e. Chassis, cards, ports, etc.) are represented as Nodes in a tree.

 [[File:TreeModel.jpg]]
'''Figure 3-2'''

Each Node will be identified by its class_id and uniquely by its uri. In addition, each node will have a series of properties associated with it that will define characteristics about the node. For example, a port node may have the maximum number of virtual ports that it can support, or QOS limits. As well properties may identify a particular node's operational state, i.e. where its up or down. Figure 3-3 show the that properties are just a another list associated with a Node.

[[File:Properties.jpg]]

'''Figure 3-3'''

==== Query and Indexing ====
Each Node and property will be indexed using a hash table design as shown in Figure 3-4. Initially, we will support hash lookups for class_id, Node_id, URI, and properties. This should satisfy the various queries for the possible use case that have been discussed to date. Each hash enter will consist of a 32-bit hash of the value that is to be indexed, the value, a pointer to the node or property, and a link to the next hash entry. The link to the next hash entry will be null unless there is a hash code collision in which case the pointer will point to the next hash element that has the same hash code value. Hash collisons are practically unavoidable when hashing a random subset of a large set of possible keys.Chained hash tables with linked lists are popular because they require only basic data structures with simple algorithms, and can use simple hash functions that are unsuitable for other methods.

[[File:IndexPic.jpg]]

'''Figure 3-4'''

The cost of a table operation is that of scanning the entries of the selected bucket for the desired key. If the distribution of keys is sufficiently uniform, the average cost of a lookup depends only on the average number of keys per bucket—that is, on the load factor.
Chained hash tables remain effective even when the number of table entries n is much higher than the number of slots. Their performance degrades more gracefully (linearly) with the load factor. For example, a chained hash table with 1000 slots and 10,000 stored keys (load factor 10) is five to ten times slower than a 10,000-slot table (load factor 1); but still 1000 times faster than a plain sequential list, and possibly even faster than a balanced search tree.
The bucket chains are implemented as ordered list, sorted by the key field; this choice approximately halves the average cost of unsuccessful lookups, compared to an unordered list. Once we are searching buckets the key field will be used to find the correct Node or property. The key is assumed to be the representation of the hash.

==== MODB API ====
TBD

=== Policy Enforcement ===
This layer of the PA is considered the south bound interface which will be module in that the initial implementation will be to OVS, via OpenFlow v1.4, but the APIs and implementation will be plugable such that other implementations can readily be adapted (i.e. other virtual switches, Cisco N1K, etc.). Functionally this layer will consist of the following:
# Rendering from the MODB to specific device commands and the communication of those commands to device.
# Status monitoring of the devices under control - this is the basis for enforcement, in that when an device event occurs we have the ability to register that state change on an object and trigger to the north bound interface.

 [[File:PolicyEnforcement.jpg]]
'''Figure 3-5'''

Status monitoring of devices under control will initially be with OVS will be via OVS's current monitoring capabilities. Initially sFlow implementation which is the current defacto standard method for this type monitoring of network flows . In addition, OVS provides command line programs for setting up monitoring such as ovs-ofctl, which a tool for monitoring OpenFlow switches. It can also show the current state of an OpenFlow switch, including features, configuration, and tables entries.
