<big>Option 1 : Invoking a remote shard using Rpc </big>

This first option does not assume the existence of Akka. With Akka some of these classes and interfaces will disappear. For example a Shard will itself be an actor and will thus not require a proxy and stub for access. In this Rpc option we're not drilling down too much into "How did the Sharded Data Store figure out where the other cluster members are?" The '''ClusterManager''' is a proxy for a component that provides that information to the Sharded Data Store


[[File:Option1-ShardingWithTransactionProxy.jpg|General Concepts|x600px]]


[[File:Create sharded data store.png|Creation of the Sharded Data Store|1000x500px]]


[[File:Create new transaction.png|Creating a new transaction|1000x500px]]


[[File:Write to transaction.png|Writing data using a transaction to a remote shard|1000x500px]]


== Open Questions/Random Thoughts ==


=== Shard Location ===

A clustered system starts up one member (process) at a time. When the very first member comes up it is not aware of any other existing members in a cluster. So it would probably have to assume that all shards are local. When the second member in a cluster comes up it needs to take ownership of some of the shards. This will involve (a) Informing member 1 of the intent to relocate the shard (2) The copying of all shard data from member 1 to member 2. 

So some questions are,

# What happens when the shard is being moved? Do all transaction requestions to that shard fail?
# What strategies can be used to avoid downtime
# Should the datastore have an “open for business” flag. That is only after all the nodes in the system are up and running will we start processing transactions?
# What happens if there are components which try adding data to the store before the store is open for business? There are certain components like topology manager which add some high-level nodes at startup. (It’s probably only one component)
