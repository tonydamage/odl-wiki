[cols="",]
|=======================================================================
|The OpenStack integration does not work in Helium SR3. Instead, please
use Helium SR2.
|=======================================================================

[[how-to-set-up-openstack-for-the-integration-with-vtn-manager]]
= How to set up OpenStack for the integration with VTN Manager

This guide describes how to set up OpenStack for integration with
OpenDaylight Controller.

While OpenDaylight Controller provides several ways to integrate with
OpenStack, this guide focus on the way which uses VTN features available
on OpenDaylight controller. In the integration, VTN Manager work as
network service provider for OpenStack. VTN Manager features, enable
OpenStack to work in pure OpenFlow environment in which all switches in
data plane are OpenFlow switch.

[[requirements]]
== Requirements

1.  OpenDaylight Controller. (VTN features must be installed.)
2.  OpenStack Control Node.
3.  OpenStack Compute Node.
4.  OpenFlow Switch like mininet (not mandatory).

::
  The VTN features support multiple OpenStack nodes. You can deploy
  multiple OpenStack Compute Nodes.
  +
  In management plane, OpenDaylight Controller, OpenStack nodes and
  OpenFlow switches should communicate with each other.
  +
  In data plane, Open vSwitches running in OpenStack nodes should
  communicate with each other through a physical or logical OpenFlow
  switches. The core OpenFlow switches are not mandatory. Therefore, you
  can directly connect to the Open vSwitch's.

image:OpenStack Demo Picture.png[OpenStack Demo Picture.png,title="OpenStack Demo Picture.png"]

[[sample-configuration]]
== Sample Configuration

Below steps depicts the configuration of single OpenStack Control node
and OpenStack Compute node setup. Our test setup is as follows

File:Odl vtn devstack setup.png[framed|center]

[[server-preparation]]
==== Server Preparation

1.  Install Ubuntu 14.04 LTS in two servers (OpenStack Control node and
Compute node respectively).
2.  While installing, Ubuntu mandates creation of a User, we created the
user "stack". We will use the same user for running devstack.
3.  Proceed with the below mentioned User Settings and Network Settings
in both the Control and Compute nodes.

[[user-settings-for-devstack]]
===== User Settings for devstack

::
  1. Log in to both servers.
  +
  2. Disable ufw

`    sudo ufw disable`

::
  3. Install the below packages (optional, provides ifconfig and route
  coammnds, handy for debugging!!)

`    sudo apt-get install net-tools`

::
  4. Edit sudo vim /etc/sudoers and add an entry as follows

`    stack ALL=(ALL) NOPASSWD: ALL`

[[network-settings]]
===== Network Settings

1.  Checked the output of ifconfig -a, two interfaces were listed eth0
and eth1 as indicated in the image above.
2.  We had connected eth0 interface to the Network where ODL Controller
is reachable.
3.  eth1 interface in both servers were connected to a different network
to act as data plane for the VM's created using the OpenStack.
4.  Manually edited the file : sudo vim /etc/network/interfaces and made
entries as follows:

`   stack@ubuntu-devstack:~/devstack$ cat /etc/network/interfaces` +
`   # This file describes the network interfaces available on your system` +
`   # and how to activate them. For more information, see interfaces(5).` +
`   # The loop-back network interface` +
`   auto lo` +
`   iface lo inet loopback` +
`   # The primary network interface` +
`   auto eth0` +
`   iface eth0 inet static` +
`        address ` +
`        netmask ` +
`        broadcast ` +
`        gateway ` +
`  auto eth1` +
`  iface eth1 inet static` +
`       address `` ` +
`       netmask `

*Note:*

` 1.Please ensure that the eth0 interface is the default route and it is able to reach the ODL_IP_ADDRESS. ` +
` 2.The entries for eth1 are not mandatory, If not set, we may have to manually do "ifup eth1" after the stacking is complete to activate the interface.`

[[finalize-the-user-and-network-settings]]
===== Finalize the User and Network Settings

1.  Please reboot both nodes after the user and network settings to have
the network settings applied to the network.
2.  Login again and check the output of ifconfig to ensure that both
interfaces are listed.

[[odl-settings-and-execution]]
==== ODL Settings and Execution

[[vtn.ini]]
===== vtn.ini

::* VTN uses the configuration parameters from *vtn.ini* file for the
OpenStack integration.

::* These values will be set for the OpenvSwitch, in all the
participating OpenStack nodes.

::* A configuration file *vtn.ini*' needs to be created manually in the
*configuration* directory.

::* The contents of *vtn.ini* should be as follows:

--------------------
bridgename=br-int
portname=eth1
protocols=OpenFlow13
failmode=secure
--------------------

:::* The values of the configuration parameters must be changed based on
the user environment.

:::** Especially, *portname* should be carefully configured, because if
the value is wrong, OpenDaylight controller fails to forward packets.

:::** Other parameters works fine as is for general use cases.

:::* *bridgename*

:::** The name of the bridge in Open vSwitch, that will be created by
OpenDaylight Controller.

:::** It must be "br-int".

:::* *portname*

:::** The name of the port that will be created in the vbridge in Open
vSwitch.

:::** *This must be the same name of the interface of OpenStack Nodes
which is used for interconnecting OpenStack Nodes in data plane.*(in our
case:eth1)

:::** By default, if vtn.ini is not created, VTN uses ens33 as portname.

:::* *protocols*

:::** OpenFlow protocol through which OpenFlow Switch and Controller
communicate.

:::** The values can be OpenFlow13 or OpenFlow10.

:::* *failmode*

:::** The value can be "standalone" or "secure".

:::** Please use *"secure"* for general use cases.

[[start-odl-controller]]
===== Start ODL Controller

1.  Please refer to the
link:Release/Helium/VTN/Installation Guide[Installation Pages] to run
ODL with VTN Feature enabled.
2.  After running ODL Controller, please ensure ODL Controller listens
to the ports:6633,6653, 6640 and 8080
3.  Please allow the ports in firewall for the devstack to be able to
communicate with ODL Controller.

*Note*

`6633/6653 - OpenFlow Ports` +
`6640 - OVS Manager Port` +
`8080 - Port for REST API`

[[devstack-setup]]
==== Devstack Setup

[[get-devstack-all-nodes]]
===== Get Devstack (All nodes)

::
  1. Install git application using

`  sudo apt-get install git`

::
  2. get devstack

`  git clone `https://git.openstack.org/openstack-dev/devstack[`https://git.openstack.org/openstack-dev/devstack`]`; `

::
  3. Switch to stable/Juno Version branch

`  cd devstack` +
`  git checkout stable/juno`

[[stack-control-node]]
===== Stack Control Node

1.  *local.conf:*
2.  cd devstack in the controller node
* Copy the contents of local.conf (devstack control node) from
OpenDaylight Virtual Tenant Network (VTN):Scripts:devstack[OpenDaylight
Virtual Tenant Network (VTN):Scripts:devstack] and save it as
*local.conf* in the *devstack*.
* Please modify the IP Address values as required.
* Stack the node

` ./stack.sh`

[[verify-control-node-stacking]]
====== Verify Control Node stacking

:*stack.sh prints out Horizon is now available at http://:8080/

:*Execute the command *sudo ovs-vsctl show* in the control node terminal
and verify if the bridge *br-int* is created.

:* Typical output of the ovs-vsctl show is indicated below

`   e232bbd5-096b-48a3-a28d-ce4a492d4b4f` +
`   Manager "tcp:192.168.64.73:6640"` +
`       is_connected: true` +
`   Bridge br-int` +
`       Controller "tcp:192.168.64.73:6633"` +
`           is_connected: true` +
`       fail_mode: secure` +
`       Port "eth1"` +
`          Interface "eth1"` +
`   ovs_version: "2.0.2"`

[[stack-compute-node]]
===== Stack Compute Node

1.  *local.conf:*
2.  cd devstack in the controller node
* Copy the contents of local.conf (devstack compute node) from
OpenDaylight Virtual Tenant Network (VTN):Scripts:devstack[OpenDaylight
Virtual Tenant Network (VTN):Scripts:devstack] and save it as
*local.conf* in the *devstack*.
* Please modify the IP Address values as required.
* Stack the node

` ./stack.sh`

[[verify-compute-node-stacking]]
====== Verify Compute Node stacking

:*stack.sh prints out This is your host ip:

:*Execute the command *sudo ovs-vsctl show* in the control node terminal
and verify if the bridge *br-int* is created.

:* The output of the ovs-vsctl show will be similar to the one seen in
control node.

[[additional-verifications]]
===== Additional Verifications

:* Please visit the ODL DLUX GUI after stacking all the nodes,
http://:8181/dlux/index.html. The switches, topology and the ports that
are currently read can be validated.

[[some-tips]]
====== Some Tips

:* If the interconnected between the OVS is not seen, Please bring up
the interface for the dataplane manually using the below comamnd

`  ifup `` `

:* Some versions of OVS, drop packets when there is a table-miss, So
please add the below flow to all the nodes with OVS version (>=2.1)

`  ovs-ofctl --protocols=OpenFlow13 add-flow br-int priority=0,actions=output:CONTROLLER`

:* Please Accept Promiscuous mode in the networks involving the
interconnect.

[[create-vm-from-devstack-horizon-gui]]
== Create VM from Devstack Horizon GUI

1.  Login to http://:8080/ to check the horizon GUI.
+
::
  image:OpenStackGui.png[OpenStackGui,title="fig:OpenStackGui"]
  +
  Enter the value for User Name as *admin* and enter the value for
  Password as *labstack*.
2.  We should first ensure both the hypervisors(control node and compute
node) are mapped under hypervisors by clicking on Hpervisors tab.
+
::
  image:Hypervisors.png[Hypervisors,title="fig:Hypervisors"]
3.  *Create a new Network from Horizon GUI.*
* Click on *Networks* Tab.
* click on the *Create Network* button.
+
::
  image:Create Network.png[Network Created,title="fig:Network Created"]
* A popup screen will appear.
* Enter network name and click *Next* button.
+
::
  image:Creare Network Step 1.png[Step 1,title="fig:Step 1"]
* Create a sub network by giving Network Address and click *Next* button
.
+
::
  image:Create Network Step 2.png[Step 2,title="fig:Step 2"]
* Specify the additional details for subnetwork (please refer the image
for your reference).
+
::
  image:Create Network Step 3.png[Step 3,title="fig:Step 3"]
* Click *Create* button .
4.  '''Create VM Instance '''
* Navigate to *Instances* tab in the GUI.
+
::
  image:Instance Creation.png[Instance
  Creation,title="fig:Instance Creation"]
* Click on *Lauch Instances* button.
* Click on *Details* tab to enter the VM details.For this demo we are
creating Ten VM's(insances).
+
::
  image:Launch Instance.png[Launch Instance,title="fig:Launch Instance"]
* In the *Networking tab*, we must select the network.
* For this we need to drag and drop the *Available networks* to
*Selected Networks* (i.e) Drag vtn1 which was created from Available
networks to Selected Networks .
* Click *Launch* to create the instances.
+
::
  image:Launch_Instance_network.png[Launch_Instance_network,title="fig:Launch_Instance_network"]
* Ten VM's will be created.
+
::
  image:Load All Instances.png[Load_All_Instances,title="fig:Load_All_Instances"]
* Click on any VM displayed in the *Instances* tab and click the
*Console* tab.
+
::
  image:Instance Console.png[Instance
  Console,title="fig:Instance Console"]
* Login to the VM console and verify with a ping commad.
+
::
  image:Instance ping.png[Instance ping,title="fig:Instance ping"]

[[verification-of-control-and-compute-node-after-vm-creation]]
== Verification of Control and Compute Node after VM creation

* Every time a new VM is created, more interfaces are added to the
br-int bridge in OVS
* Use *sudo ovs-vsctl show* to list the number of interfaces added
* Please visit the dlux GUI to list the new nodes in every switch.

[[faqs]]
= FAQ's

[[vtn-name-maps-exactly-to-the-openstack-tenantproject-id]]
== VTN "name" maps exactly to the Openstack "Tenant/Project ID"?

`  The maximum length supported by VTN for Vtn Name is 31 bytes , So the  version field supplied from the OpenStack` +
`  supplied UUID is removed to make it usable by VTN, The Similar implementation is applied for Network ID  and Port ID.`

[[does-vtn-openstack-integration-support-vlan]]
== Does VTN & OpenStack integration support VLAN?

`  Vlan Mapping is not supported for OpenStack integration.Port mapping happens automatically to provide networking.`

[[how-does-vtn-isolate-the-traffic-form-different-openstack-tenant]]
== How does VTN isolate the traffic form different OpenStack Tenant?

`  Whenever a new Network with Subnets is created from OpenStack GUI or command line, there will be a new vbridge created.` +
`  When VM's are created using the Network  Vbridge interfaces and portmaps will be added under the particular vbridge` +
`  to provide networking to the vM's. By adding new vbridges, the networks created are isolated.`

[[why-vbridge-and-interfaces-names-are-assigned-as-the-uuids-in-vtn-rather-the-one-specified-as-inputs-in-the-openstack]]
== Why Vbridge and interfaces names are assigned as the UUIDs in VTN
rather the one specified as inputs in the Openstack?

`  The UUID created in Openstack are mapped to names in VTN. This is done to maintain the uniqueness and naming requirements` +
`  in VTN network. The name provided in Openstack are mapped to the description field for the respective elements in the VTN.`

[[there-are-three-vms-vm1-vm2-and-vm3.-how-vm3-communicates-with-vm2-and-vm1-using-vtn-manager-and-openstack]]
== There are three VMs VM1, Vm2 and Vm3. How VM3 communicates with VM2
and VM1 using VTN Manager and Openstack?

`  One can create single or more vBridges interface and portmap for the port in which VM3 is connected, that will enable the ` +
`  connectivity.`

[[once-a-network-is-added-in-openstack-it-adds-a-vbridge-in-vtn-then-how-to-add-a-new-tenant]]
== Once a network is added in Openstack, it adds a vBridge in VTN then
How to add a new tenant?

`  The Tenant in Openstack is mapped to the VTN in VTN networks and the network is mapped to the vBridge within the VTN. If a new ` +
`  tenant is created in Openstack then it will be mapped to new VTN.`

[[is-it-feasible-to-use-the-same-name-as-it-is-in-openstack-for-vtn-vbridge-in-vtn-manager-implementation]]
== Is it feasible to use the same name as it is in Openstack for VTN,
vBridge in VTN manager implementation?

`  To maintain uniqueness of the VTN, vBridge identifiers within the VTN implementation, we cannot map the names used in Openstack inside` +
`  VTN Manager.`

[[references]]
= References

http://devstack.org/guides/multinode-lab.html[devstack_multinode_help]

http://www.siliconloons.com/opendaylight-integration-with-openstack-has-merged-into-icehouse/[odl_openstack_integration_refernce]

http://networkstatic.net/opendaylight-openstack-integration-devstack-fedora-20/[odl_openstack_fedora_20_reference]

Media:Vtn demo hackfest 2014 march.pdf[HackFest Demo Material (OVSDB-VTN
Neutron Integration)]

Category:OpenDaylight Virtual Tenant Network[Category:OpenDaylight
Virtual Tenant Network]
