[[opflex-policy-agent-architecture]]
== OpFlex Policy Agent Architecture

[[the-fine-print]]
=== The Fine Print

This document is considered a working document in that it is intended to
be a place holder for the project and as the Policy Agent under goes
development, this document will change as well and at time be outdated.

[[overview]]
=== Overview

This document describes the architecture proposed for the open source
Policy Agent for the implementation that will implement the OpFlex
protocol. Before one discusses the details of the architecture and
assumptions therein, an overview of where and how the Policy Agent will
fix into and overall system design is in order. The following is that
overview of a Policy systems and its various functions. The policy
agent’s function is to exchange and enforce policy, acting as a
participant in a larger policy management system. policy system. Figure
1-1 is an example of such a system. The agent is a Policy Element (PE),
which requests Policy Resolution and receives Policy Updates from a
Policy Repository (PR). The agent can also indicate the declaration of
new End Points to an End Point Registry (EPR), and receive Policy
Resolutions and Updates for the End Points. Status information is sent
to an Observer, which collects and archives the status. The agent can
also trigger behaviors in peering Policy Elements, using the Policy
Trigger message. A more complete description of an Policy system can be
found in [1].

image:S1mdMlrjSoE4t3CGd59GX8A.png[S1mdMlrjSoE4t3CGd59GX8A.png,title="S1mdMlrjSoE4t3CGd59GX8A.png"]

[[policy-and-policy-resolution]]
==== Policy and Policy Resolution

A primary function of the policy architecture is the delivery and
maintenance of Manage Object (MO) subtrees. Each Policy Element has a
Managed Object Store, which provides a means for local caching of policy
in the form of Managed Objects. Managed Objects are considered subtrees
of a larger Management Information Tree (MIT). The MIT is the superset
of all possible policies, and is generated from a user-defined policy
model. There are two types of policy models. One is a “Logical Model” in
which fabric-specific details are abstracted into an equivalent logical
representation. The other is a “Concrete Model” in which the objects in
the model refer to physical network elements. The Logical Model is used
to create a MIT that can be imported in the policy controller, as well
as MO library that can be integrated in the agent (Figure 1-3).

image:SoQ8NTo_lvD95rDSmZRQ-Ow.png [SoQ8NTo_lvD95rDSmZRQ-Ow.png ,title="SoQ8NTo_lvD95rDSmZRQ-Ow.png "]

*Figure 1-3: Generated Policy Model*

Each type of policy is uniquely identified in a given context by its
name, where context can be specific to a tenant, a shared common tenant,
etc. Resources that use a policy refer to this policy by its name, and a
hierarchical closest matching policy is resolved. If no named match
exists, a default policy is resolved.

Policy resolution is typically implicit, meaning that it is triggered
via a set of internal APIs in the PE as a side effect of a change /
stimulus, such as an endpoint attach. Policy resolution consists of
sending logical policies to Policy Elements, which maintain read-only
copies of the logical policies and apply changes to corresponding
concrete model objects. Whenever possible, sets of related policies are
resolved together in a single transaction to Policy Elements.

The Policy Repository persists information about which policies are in
use and where they have been resolved in an internal registry. When
there are subsequent changes to policies -- such as property
modifications and lifecycle changes (creation, deletion) -- the Policy
Repository sends update notifications to Policy Elements where the
affected policies are in use. It is the responsibility of Policy
Repository to push the updates to policies that it owns to all the
policy clients of the policy. For each policy, the Policy Repository
maintains the list of policy clients and policy consumers. As mentioned
in above, when a policy is resolved, all policies with that name in the
hierarchy are in-scope policies and would be resolved. Whenever a policy
is updated, the updated policy is pushed down to all policy clients. The
Policy Update message is only used to provide updates to policies that
have already been provided to a Policy Element, and not to install an
entirely new policy. The Policy Resolution message from the Policy
Element must be used to request new policies (i.e. MO sub-trees that the
PE doesn’t yet have).

[[opflex-background]]
=== OpFlex Background

To implement declarative control, a new mechanism is required to
transfer abstract policy from a network policy controller to a set of
smart devices capable of rendering abstract policy. Unfortunately,
existing protocols such as OVSDB favor imperative models and rigid
schematics, so they are not appropriate for this use case. In Fact,
devOps tools such as Puppet or CFEngine take a similar approach to
OpFlex in using declarative languages to configure server resources.

OpFlex was designed to augment rather than replace these tools by
focusing on additional requirements of the network and policies that
must span multiple network devices. For example, OpFlex includes a
native mechanism for identity resolution used to define declarative
policies between two different network endpoints.Cisco, along with
partners including Microsoft, Red Hat, Citrix, F5, Canonical, and
Embrane, developed OpFlex to address this challenge. OpFlex is an open
and extensible policy protocol for transferring abstract policy in XML
or JavaScript Object Notation (JSON) between a network policy controller
such as the Cisco APIC and any device, including hypervisor switches,
physical switches, and Layer 4 through 7 network services. Cisco and its
partners are working through the IETF and open source community to
standardize OpFlex and provide a reference implementation.

image:CFPOpflexDrawing1.jpg[CFPOpflexDrawing1.jpg,title="CFPOpflexDrawing1.jpg"]

[[opflex-description]]
=== OpFlex Description

OpFlex is designed to allow a data exchange of a set of managed objects
that is defined as part of an informational model. OpFlex itself does
not dictate the information model and can be used with any tree-based
abstract model in which each node in the tree has a universal resource
identifier (URI) associated with it.

The protocol is designed to support XML and JSON (as well as the binary
encoding used in some scenarios) and to use standard remote procedure
call (RPC) mechanisms such as JSON-RPC over TCP. The use of a secure
channel through Secure Sockets Layer (SSL) and Transport Security Layer
(TSL) is also recommended.

The protocol defines a number of logical constructs required for its
operation (Figure 2).

image:Don2.jpg[Don2.jpg,title="Don2.jpg"]

[[policy-repository]]
==== Policy Repository

The policy repository (PR) is a logically centralized entity containing
the definition of all policies governing the behavior of the system. In
Cisco ACI, this function is performed by the Cisco APIC or by the leaf
nodes of the network fabric. The policy authority handles policy
resolution requests from each policy element.

[[policy-element-policy-agent]]
==== Policy Element (Policy Agent)

A policy element (PE) is a logical abstraction for a physical or virtual
device that implements and enforces policy. This is where the Policy
Agent describe in detail herein resides. Policy elements are responsible
for requesting portions of the policy from the policy authority as new
endpoints connect, disconnect, or change. Additionally, policy elements
are responsible for rendering that policy from an abstract form into a
concrete form that maps to their internal capabilities. This process is
a local operation and can function differently on each device as long as
the semantics of the policy are honored.

[[endpoint-registry]]
==== Endpoint Registry

The endpoint registry (ER) stores the current operation state (identity,
location, etc.) of each endpoint (EP) in the system. The endpoint
registry receives information about each endpoint from the local policy
element and then can share it with other policy elements in the system.
The endpoint registry may be physically co-located with the policy
authority, but it may also be distributed in the network fabric itself.
In Cisco’s ACI solution, the endpoint registry actually lives in a
distributed database within the network itself to provide additional
performance and resiliency.

[[opflex-protocol-messages]]
=== Opflex Protocol Messages

Table 1 Summarizes the RPC methods that OpFlex supports. It is not
intended to provide a full description, but to to show how different
entities interact through the protocol.

Table 1. RPC Methods Supported by OpFlex.

image:Don3.jpg[Don3.jpg,title="Don3.jpg"]

[[policy-agent-architecture-discussion]]
== Policy Agent Architecture Discussion

The Policy Agent (PA) provides a framework for creating families of
policy agents, enabling policy enforcement across a wide variety of
functions, such as compute, storage, and networking. The agent connects
to other components in the policy fabric, and interacts with them to
manage its policy state. The PA diagram shown in Figure 3.0, is the
basic building blocks that are to be discussed in the following
sections. For the most part there are 3 section that makeup the design.

image:PolicyAgentOverview.jpg[PolicyAgentOverview.jpg,title="PolicyAgentOverview.jpg"]

1.  Policy Management - responsible for the communications to the policy
systems (i.e. ODL, Openstack, APIC, etc.), and the marshaling of the
OpFlex protocol into the Managed Objects (MOB).
1.  This will encompass a stream Based communications API and can easily
support multiple protocols, i.e. TCP/UDP/SSL.
1.  The streams interface will support both active, initiate connections
to the controller, and passive based communications, listener.
2.  Will support a plug-able payload data marshaling and de-marshaling
for JSON and XML.
3.  Protocol management will be implemented in this layer as well.
Protocol management will instigate the initiation of communications to
the policy controllers and the re-establishment of connection upon a
failure.
1.  This implies that as discovery of policy entities occurs their
details will be persisted to the file system such that they can be
recovered upon a restart of the of the PA.
2.  Managed Objects DB (MODB) - this represent that accumulation of
policies that have been rendered into a hierarchical tree model and
represent real-time status from the actual physical devices under
enforcement. An abstract representation of network resources that are
managed. With "representation", I mean not the actual device that is
managed, but also the device driver, that communicates with the
device.The database, where all managed objects are stored, is called the
Managed Object Database . The MO is "dynamic" and communicates with
other network resources that are managed.
3.  Policy Enforcement - This layer presents itself as a series for APIs
that are leverage to communicate to devices under management (i..e.
switches, routers, storage, compute nodes, etc.). The intention here is
to provide a plugable interface such that the Policy agent can be used
with multiple devices.
1.  Initially, the OpenvSwitch (OVS) using OpenFlow v1.4 will be target
as a representative implementation.

[[policy-management-layer]]
=== Policy Management Layer

The policy management layer embodies the communications to the north
bound of the PA and the protocol management, in the case of this design
it will be OpFlex, but it would not preclude another policy protocol.
This layer consist of the following sections of development:

1.  Stream API
2.  Session Manager
3.  Presentation Manager

image:PAMgmtLayer.jpg[PAMgmtLayer.jpg,title="PAMgmtLayer.jpg"]

[[stream-api]]
==== Stream API

This would be base on the OVS library stream interface where the actual
details protocol being used for communications is abstracted from the
upper layer. A stream_class is present which provides the necessary
call-backs to support the underlying protocols (i.e. TCP, SSL, RPCJSON).
This approach obviously provides a framework from which to add further
protocol support. The pstream_class definition is as follows:

struct pstream_class \{

`   /* Prefix for connection names, e.g. "ptcp", "pssl", "punix". */` +
`   const char *name;`

`   /* True if this pstream needs periodic probes to verify connectivity.  For` +
`    * pstreams which need probes, it can take a long time to notice the` +
`    * connection was dropped. */` +
`   bool needs_probes;`

`   /* Attempts to start listening for stream connections.  'name' is the full` +
`    * connection name provided by the user, e.g. "ptcp:1234".  This name is` +
`    * useful for error messages but must not be modified.` +
`    *` +
`    * 'suffix' is a copy of 'name' following the colon and may be modified.` +
`    * 'dscp' is the DSCP value that the new connection should use in the IP` +
`    * packets it sends.` +
`    *` +
`    * Returns 0 if successful, otherwise a positive errno value.  If` +
`    * successful, stores a pointer to the new connection in '*pstreamp'.` +
`    *` +
`    * The listen function must not block.  If the connection cannot be` +
`    * completed immediately, it should return EAGAIN (not EINPROGRESS, as` +
`    * returned by the connect system call) and continue the connection in the` +
`    * background. */` +
`   int (*listen)(const char *name, char *suffix, struct pstream **pstreamp,` +
`                 uint8_t dscp);`

`   /* Closes 'pstream' and frees associated memory. */` +
`   void (*close)(struct pstream *pstream);`

`   /* Tries to accept a new connection on 'pstream'.  If successful, stores` +
`    * the new connection in '*new_streamp' and returns 0.  Otherwise, returns` +
`    * a positive errno value.` +
`    *` +
`    * The accept function must not block waiting for a connection.  If no` +
`    * connection is ready to be accepted, it should return EAGAIN. */` +
`   int (*accept)(struct pstream *pstream, struct stream **new_streamp);`

`   /* Arranges for the poll loop to wake up when a connection is ready to be` +
`    * accepted on 'pstream'. */` +
`   void (*wait)(struct pstream *pstream);`

`   /* Set DSCP value of the listening socket. */` +
`   int (*set_dscp)(struct pstream *pstream, uint8_t dscp);`

};

It is important to note that all the socket interface are perform in a
non-blocking mode. Using this layer to perform connection initiation is
fairly obvious but to perform listener its basically a
stream.c:pstream_accept which will not block waiting for a connection.
If no connection is ready to be accepted, it returns EAGAIN immediately.
But if block is desired, as is with most listeners, there is also
stream.c:pstream_accept_block, which does block until a connection is
ready or until an error occurs.

[[session-manager]]
==== Session Manager

The session manager (SM) layer should support the ability to provide a
connection list of active and inactive connections, defined by a state
of the connection. Connection to north bound systems should be held open
until either they are closed by the PA or the peer on the the other end.
The connection list should be defined by the config file variable and if
the connection list is full, the LRU (Least Recently Used) policy should
be used to either open or accept another connection. In addition, a
session timeout thread should be used to timeout sessions in the session
list. This timeout will be config file controlled. The reason for
keeping the session list efficient is if there is no need to keep a
connection active, i.e. lack of activity, then its best to free up the
session list slot and the memory that a connection consumes. The SM
should have the ability to perform marshaling/de-marshaling of data
based upon the connection and the presentations managers connection
setup information. OpFlex provides a Identify message which will provide
the type connectivity_info and roles information. The session manager
layer should also be the identity that sets up the PA's listener based
upon configuration information found in the config file.

[[presentation-manager]]
==== Presentation Manager

The Presentation Manager (PM) establishes context OpFlex entities, in
which the OpFlex entities may use different syntax and semantics see
OpFlex IETF draft, draft-smith-opflex-00b specification. The dealings of
OpFlex protocol, i.e. Discovery and Identify. This layer provides
independence from data representation (e.g., JSON)/XML/etc.) by
translating between application and network formats. The presentation
layer transforms data into the form that the application accepts. This
layer formats and encrypts data to be sent across a network. It is
sometimes called the syntax layer. As the presentation Layer discovers
items in the policy network (i.e. controllers, policy repositories
(prime data and replicated data), this layer should make a map of this
information which should include the enough details such that it can be
persisted to disk. Each time the PA initializes (e.g. after a crash),
and if the file is available on disk, it should be assumed that the
information should be restored from this file and the presentation layer
should try and re-establish connections to all know systems (i.e.
identify message). This allow that if in the case of a failure of the
PA, it can recover its connections to try and ensure establishment to
the policy systems. This will speed up the crash recovery because each
policy that is in the MODB will have to be re-confirmed (rendered with
the upper controllers).

[[managed-objects-database-modb]]
=== Managed Objects Database (MODB)

This represent that accumulation of policies that have been rendered
into a hierarchical tree model and represent real-time status from the
actual physical devices under enforcement. An abstract representation of
network resources that are managed. With "representation", I mean not
the actual device that is managed, but also the device driver, that
communicates with the device.The database, where all managed objects are
stored, is called the Managed Object Database . The MO is "dynamic" and
communicates with other network resources that are managed. The MODB is
essentially an accumulation of lists and hash lookup tables that are
designed for usability for the policy storage and for quick retrieval of
data though a common API. The MODB's lookups are some what static in
that they are designed for optimum index to data that we will support
look ups for. By no means are they static in the sense that data in
those index look ups table will be static its just the optimized look
ups will be support using the index look ups. The structure of the MODB
is showing in Figure 3-1. The Figure is intended to give a general idea
of the internal structure of the MODb and its relationship to the
indexing and the API that both the southbound and northbound interface
will use to access it.

image:MODB.jpg[MODB.jpg,title="fig:MODB.jpg"] *Figure 3-1*

At the core of the model is the Node entity that will define all data
relationships in the system. One node's difference from another will be
defined by its lri and class_id. For example a chassis verses a port
will be defined by different class_ids, but each individual port will be
differentiated by its id and uri. This allows for the model to be very
simplistic but very functional. Each node will associated to its parent,
assuming it has one, if not this will NULL, and its children, which will
just be a list head pointing to the lik list of all the nodes that make
up its children nodes. An example of an abstracted model is shown in
Figure 3-2, where each of the items (i.e. Chassis, cards, ports, etc.)
are represented as Nodes in a tree.

image:TreeModel.jpg[`TreeModel.jpg`,title="TreeModel.jpg"]

*Figure 3-2*

Each Node will be identified by its class_id and uniquely by its uri. In
addition, each node will have a series of properties associated with it
that will define characteristics about the node. For example, a port
node may have the maximum number of virtual ports that it can support,
or QOS limits. As well properties may identify a particular node's
operational state, i.e. where its up or down. Figure 3-3 show the that
properties are just a another list associated with a Node.

image:Properties.jpg[Properties.jpg,title="Properties.jpg"]

*Figure 3-3*

[[query-and-indexing]]
==== Query and Indexing

Each Node and property will be indexed using a hash table design as
shown in Figure 3-4. Initially, we will support hash lookups for
class_id, Node_id, URI, and properties. This should satisfy the various
queries for the possible use case that have been discussed to date. Each
hash enter will consist of a 32-bit hash of the value that is to be
indexed, the value, a pointer to the node or property, and a link to the
next hash entry. The link to the next hash entry will be null unless
there is a hash code collision in which case the pointer will point to
the next hash element that has the same hash code value. Hash collisons
are practically unavoidable when hashing a random subset of a large set
of possible keys.Chained hash tables with linked lists are popular
because they require only basic data structures with simple algorithms,
and can use simple hash functions that are unsuitable for other methods.

image:IndexPic.jpg[IndexPic.jpg,title="IndexPic.jpg"]

*Figure 3-4*

The cost of a table operation is that of scanning the entries of the
selected bucket for the desired key. If the distribution of keys is
sufficiently uniform, the average cost of a lookup depends only on the
average number of keys per bucket—that is, on the load factor. Chained
hash tables remain effective even when the number of table entries n is
much higher than the number of slots. Their performance degrades more
gracefully (linearly) with the load factor. For example, a chained hash
table with 1000 slots and 10,000 stored keys (load factor 10) is five to
ten times slower than a 10,000-slot table (load factor 1); but still
1000 times faster than a plain sequential list, and possibly even faster
than a balanced search tree. The bucket chains are implemented as
ordered list, sorted by the key field; this choice approximately halves
the average cost of unsuccessful lookups, compared to an unordered list.
Once we are searching buckets the key field will be used to find the
correct Node or property. The key is assumed to be the representation of
the hash.

[[modb-api]]
==== MODB API

TBD

[[policy-enforcement]]
=== Policy Enforcement

This layer of the PA is considered the south bound interface which will
be module in that the initial implementation will be to OVS, via
OpenFlow v1.4, but the APIs and implementation will be plugable such
that other implementations can readily be adapted (i.e. other virtual
switches, Cisco N1K, etc.). Functionally this layer will consist of the
following:

1.  Rendering from the MODB to specific device commands and the
communication of those commands to device.
2.  Status monitoring of the devices under control - this is the basis
for enforcement, in that when an device event occurs we have the ability
to register that state change on an object and trigger to the north
bound interface.

image:PolicyEnforcement.jpg[`PolicyEnforcement.jpg`,title="PolicyEnforcement.jpg"]

*Figure 3-5*

Status monitoring of devices under control will initially be with OVS
will be via OVS's current monitoring capabilities. Initially sFlow
implementation which is the current defacto standard method for this
type monitoring of network flows . In addition, OVS provides command
line programs for setting up monitoring such as ovs-ofctl, which a tool
for monitoring OpenFlow switches. It can also show the current state of
an OpenFlow switch, including features, configuration, and tables
entries.
